// Generated by the Scala Plugin for the Protocol Buffer Compiler.
// Do not edit!
//
// Protofile syntax: PROTO3

package com.intel.analytics.zoo.serving.grpc

@SerialVersionUID(0L)
final case class ModelsReply(
    inferenceModelMetaDatas: _root_.scala.Seq[com.intel.analytics.zoo.serving.grpc.InferenceModelGRPCMetaData] = _root_.scala.Seq.empty,
    clusterServingMetaDatas: _root_.scala.Seq[com.intel.analytics.zoo.serving.grpc.ClusterServingGRPCMetaData] = _root_.scala.Seq.empty,
    unknownFields: _root_.scalapb.UnknownFieldSet = _root_.scalapb.UnknownFieldSet.empty
    ) extends scalapb.GeneratedMessage with scalapb.lenses.Updatable[ModelsReply] {
    @transient
    private[this] var __serializedSizeCachedValue: _root_.scala.Int = 0
    private[this] def __computeSerializedValue(): _root_.scala.Int = {
      var __size = 0
      inferenceModelMetaDatas.foreach { __item =>
        val __value = __item
        __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
      }
      clusterServingMetaDatas.foreach { __item =>
        val __value = __item
        __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
      }
      __size += unknownFields.serializedSize
      __size
    }
    override def serializedSize: _root_.scala.Int = {
      var read = __serializedSizeCachedValue
      if (read == 0) {
        read = __computeSerializedValue()
        __serializedSizeCachedValue = read
      }
      read
    }
    def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
      inferenceModelMetaDatas.foreach { __v =>
        val __m = __v
        _output__.writeTag(1, 2)
        _output__.writeUInt32NoTag(__m.serializedSize)
        __m.writeTo(_output__)
      };
      clusterServingMetaDatas.foreach { __v =>
        val __m = __v
        _output__.writeTag(2, 2)
        _output__.writeUInt32NoTag(__m.serializedSize)
        __m.writeTo(_output__)
      };
      unknownFields.writeTo(_output__)
    }
    def clearInferenceModelMetaDatas = copy(inferenceModelMetaDatas = _root_.scala.Seq.empty)
    def addInferenceModelMetaDatas(__vs: com.intel.analytics.zoo.serving.grpc.InferenceModelGRPCMetaData*): ModelsReply = addAllInferenceModelMetaDatas(__vs)
    def addAllInferenceModelMetaDatas(__vs: Iterable[com.intel.analytics.zoo.serving.grpc.InferenceModelGRPCMetaData]): ModelsReply = copy(inferenceModelMetaDatas = inferenceModelMetaDatas ++ __vs)
    def withInferenceModelMetaDatas(__v: _root_.scala.Seq[com.intel.analytics.zoo.serving.grpc.InferenceModelGRPCMetaData]): ModelsReply = copy(inferenceModelMetaDatas = __v)
    def clearClusterServingMetaDatas = copy(clusterServingMetaDatas = _root_.scala.Seq.empty)
    def addClusterServingMetaDatas(__vs: com.intel.analytics.zoo.serving.grpc.ClusterServingGRPCMetaData*): ModelsReply = addAllClusterServingMetaDatas(__vs)
    def addAllClusterServingMetaDatas(__vs: Iterable[com.intel.analytics.zoo.serving.grpc.ClusterServingGRPCMetaData]): ModelsReply = copy(clusterServingMetaDatas = clusterServingMetaDatas ++ __vs)
    def withClusterServingMetaDatas(__v: _root_.scala.Seq[com.intel.analytics.zoo.serving.grpc.ClusterServingGRPCMetaData]): ModelsReply = copy(clusterServingMetaDatas = __v)
    def withUnknownFields(__v: _root_.scalapb.UnknownFieldSet) = copy(unknownFields = __v)
    def discardUnknownFields = copy(unknownFields = _root_.scalapb.UnknownFieldSet.empty)
    def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
      (__fieldNumber: @_root_.scala.unchecked) match {
        case 1 => inferenceModelMetaDatas
        case 2 => clusterServingMetaDatas
      }
    }
    def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
      _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
      (__field.number: @_root_.scala.unchecked) match {
        case 1 => _root_.scalapb.descriptors.PRepeated(inferenceModelMetaDatas.iterator.map(_.toPMessage).toVector)
        case 2 => _root_.scalapb.descriptors.PRepeated(clusterServingMetaDatas.iterator.map(_.toPMessage).toVector)
      }
    }
    def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToUnicodeString(this)
    def companion = com.intel.analytics.zoo.serving.grpc.ModelsReply
    // @@protoc_insertion_point(GeneratedMessage[grpc.ModelsReply])
}

object ModelsReply extends scalapb.GeneratedMessageCompanion[com.intel.analytics.zoo.serving.grpc.ModelsReply] {
  implicit def messageCompanion: scalapb.GeneratedMessageCompanion[com.intel.analytics.zoo.serving.grpc.ModelsReply] = this
  def parseFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): com.intel.analytics.zoo.serving.grpc.ModelsReply = {
    val __inferenceModelMetaDatas: _root_.scala.collection.immutable.VectorBuilder[com.intel.analytics.zoo.serving.grpc.InferenceModelGRPCMetaData] = new _root_.scala.collection.immutable.VectorBuilder[com.intel.analytics.zoo.serving.grpc.InferenceModelGRPCMetaData]
    val __clusterServingMetaDatas: _root_.scala.collection.immutable.VectorBuilder[com.intel.analytics.zoo.serving.grpc.ClusterServingGRPCMetaData] = new _root_.scala.collection.immutable.VectorBuilder[com.intel.analytics.zoo.serving.grpc.ClusterServingGRPCMetaData]
    var `_unknownFields__`: _root_.scalapb.UnknownFieldSet.Builder = null
    var _done__ = false
    while (!_done__) {
      val _tag__ = _input__.readTag()
      _tag__ match {
        case 0 => _done__ = true
        case 10 =>
          __inferenceModelMetaDatas += _root_.scalapb.LiteParser.readMessage[com.intel.analytics.zoo.serving.grpc.InferenceModelGRPCMetaData](_input__)
        case 18 =>
          __clusterServingMetaDatas += _root_.scalapb.LiteParser.readMessage[com.intel.analytics.zoo.serving.grpc.ClusterServingGRPCMetaData](_input__)
        case tag =>
          if (_unknownFields__ == null) {
            _unknownFields__ = new _root_.scalapb.UnknownFieldSet.Builder()
          }
          _unknownFields__.parseField(tag, _input__)
      }
    }
    com.intel.analytics.zoo.serving.grpc.ModelsReply(
        inferenceModelMetaDatas = __inferenceModelMetaDatas.result(),
        clusterServingMetaDatas = __clusterServingMetaDatas.result(),
        unknownFields = if (_unknownFields__ == null) _root_.scalapb.UnknownFieldSet.empty else _unknownFields__.result()
    )
  }
  implicit def messageReads: _root_.scalapb.descriptors.Reads[com.intel.analytics.zoo.serving.grpc.ModelsReply] = _root_.scalapb.descriptors.Reads{
    case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
      _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage eq scalaDescriptor), "FieldDescriptor does not match message type.")
      com.intel.analytics.zoo.serving.grpc.ModelsReply(
        inferenceModelMetaDatas = __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).map(_.as[_root_.scala.Seq[com.intel.analytics.zoo.serving.grpc.InferenceModelGRPCMetaData]]).getOrElse(_root_.scala.Seq.empty),
        clusterServingMetaDatas = __fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).map(_.as[_root_.scala.Seq[com.intel.analytics.zoo.serving.grpc.ClusterServingGRPCMetaData]]).getOrElse(_root_.scala.Seq.empty)
      )
    case _ => throw new RuntimeException("Expected PMessage")
  }
  def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = FrontEndGRPCProto.javaDescriptor.getMessageTypes().get(7)
  def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = FrontEndGRPCProto.scalaDescriptor.messages(7)
  def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[_] = {
    var __out: _root_.scalapb.GeneratedMessageCompanion[_] = null
    (__number: @_root_.scala.unchecked) match {
      case 1 => __out = com.intel.analytics.zoo.serving.grpc.InferenceModelGRPCMetaData
      case 2 => __out = com.intel.analytics.zoo.serving.grpc.ClusterServingGRPCMetaData
    }
    __out
  }
  lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[_ <: _root_.scalapb.GeneratedMessage]] = Seq.empty
  def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[_] = throw new MatchError(__fieldNumber)
  lazy val defaultInstance = com.intel.analytics.zoo.serving.grpc.ModelsReply(
    inferenceModelMetaDatas = _root_.scala.Seq.empty,
    clusterServingMetaDatas = _root_.scala.Seq.empty
  )
  implicit class ModelsReplyLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, com.intel.analytics.zoo.serving.grpc.ModelsReply]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, com.intel.analytics.zoo.serving.grpc.ModelsReply](_l) {
    def inferenceModelMetaDatas: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Seq[com.intel.analytics.zoo.serving.grpc.InferenceModelGRPCMetaData]] = field(_.inferenceModelMetaDatas)((c_, f_) => c_.copy(inferenceModelMetaDatas = f_))
    def clusterServingMetaDatas: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Seq[com.intel.analytics.zoo.serving.grpc.ClusterServingGRPCMetaData]] = field(_.clusterServingMetaDatas)((c_, f_) => c_.copy(clusterServingMetaDatas = f_))
  }
  final val INFERENCEMODELMETADATAS_FIELD_NUMBER = 1
  final val CLUSTERSERVINGMETADATAS_FIELD_NUMBER = 2
  def of(
    inferenceModelMetaDatas: _root_.scala.Seq[com.intel.analytics.zoo.serving.grpc.InferenceModelGRPCMetaData],
    clusterServingMetaDatas: _root_.scala.Seq[com.intel.analytics.zoo.serving.grpc.ClusterServingGRPCMetaData]
  ): _root_.com.intel.analytics.zoo.serving.grpc.ModelsReply = _root_.com.intel.analytics.zoo.serving.grpc.ModelsReply(
    inferenceModelMetaDatas,
    clusterServingMetaDatas
  )
  // @@protoc_insertion_point(GeneratedMessageCompanion[grpc.ModelsReply])
}
